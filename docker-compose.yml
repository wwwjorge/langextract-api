version: '3.8'

services:
  langextract-api:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    image: langextract-api:latest
    container_name: langextract-api
    restart: unless-stopped
    ports:
      - "${API_PORT:-7436}:8000"
    environment:
      # API Configuration
      - API_KEY=${API_KEY:-your_api_key_here}
      - DEFAULT_MODEL=${DEFAULT_MODEL:-llama3.2:3b}
      - UPLOAD_DIR=${UPLOAD_DIR:-/app/uploads}
      - MAX_FILE_SIZE=${MAX_FILE_SIZE:-50}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      
      # Model Configuration
      - DEFAULT_TEMPERATURE=${DEFAULT_TEMPERATURE:-0.3}
      
      # File Upload Settings
      - MAX_FILE_SIZE_MB=${MAX_FILE_SIZE_MB:-100}
      - ALLOWED_FILE_EXTENSIONS=${ALLOWED_FILE_EXTENSIONS:-.txt,.pdf,.docx,.md,.json}
      
      # CORS Configuration
      - CORS_ORIGINS=${CORS_ORIGINS:-*}
      - ALLOWED_METHODS=${ALLOWED_METHODS:-GET,POST,PUT,DELETE,OPTIONS}
      - ALLOWED_HEADERS=${ALLOWED_HEADERS:-*}
      
      # Timeout Configuration
      - REQUEST_TIMEOUT=${REQUEST_TIMEOUT:-300}
      - LLM_TIMEOUT=${LLM_TIMEOUT:-180}
      
      # Provider URLs (Linux/WSL compatible)
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://172.17.0.1:11434}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - GEMINI_BASE_URL=${GEMINI_BASE_URL:-https://generativelanguage.googleapis.com/v1beta}
      - CLOUDFLARE_BASE_URL=${CLOUDFLARE_BASE_URL:-https://api.cloudflare.com/client/v4/accounts}
      - CLOUDFLARE_ACCOUNT_ID=${CLOUDFLARE_ACCOUNT_ID:-}
      
      # API Keys
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - CLOUDFLARE_API_TOKEN=${CLOUDFLARE_API_TOKEN:-}
      
      # Security Headers
      - X_FRAME_OPTIONS=${X_FRAME_OPTIONS:-SAMEORIGIN}
      - X_CONTENT_TYPE_OPTIONS=${X_CONTENT_TYPE_OPTIONS:-nosniff}
      - X_XSS_PROTECTION=${X_XSS_PROTECTION:-1; mode=block}
      - REFERRER_POLICY=${REFERRER_POLICY:-strict-origin-when-cross-origin}
      - CONTENT_SECURITY_POLICY=${CONTENT_SECURITY_POLICY:-default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; connect-src 'self'}
    
    volumes:
      - langextract-uploads:/app/uploads
      - langextract-logs:/app/logs
      - langextract-cache:/app/cache
    
    networks:
      - langextract-network
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    deploy:
      resources:
      - "app.name=langextract-api"
      - "app.version=${APP_VERSION:-latest}"
      - "app.description=LangExtract API for document text extraction"
      - "maintainer=jorge@yourdomain.com"

  # Optional: Redis for caching (uncomment if needed)
  # redis:
  #   image: redis:7-alpine
  #   container_name: langextract-redis
  #   restart: unless-stopped
  #   volumes:
  #     - langextract-redis:/data
  #   networks:
  #     - langextract-network
  #   healthcheck:
  #     test: ["CMD", "redis-cli", "ping"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '0.5'
  #         memory: 256M

volumes:
  langextract-uploads:
    driver: local
    name: langextract-uploads
  langextract-logs:
    driver: local
    name: langextract-logs
  langextract-cache:
    driver: local
    name: langextract-cache
  # langextract-redis:
  #   driver: local
  #   name: langextract-redis

networks:
  langextract-network:
    driver: bridge
